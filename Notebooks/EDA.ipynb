{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import langdetect\n",
    "import nltk\n",
    "import gutenberg\n",
    "from gutenberg.query import get_etexts\n",
    "from gutenberg.acquire import load_etext\n",
    "from gutenberg.cleanup import strip_headers\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "caps = \"([A-Z])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
    "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "websites = \"[.](com|net|org|io|gov)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_language_stopword(input_text):\n",
    "    input_words = nltk.wordpunct_tokenize(input_text)\n",
    "\n",
    "    likelihood = {}\n",
    "    for language in nltk.corpus.stopwords._fileids:\n",
    "        likelihood[language] = len(set(input_words) & set(nltk.corpus.stopwords.words(language)))\n",
    "    language = sorted(likelihood, key=likelihood.get, reverse=True)[0]\n",
    "    likelihood = {k:v for k, v in likelihood.items() if v}\n",
    "    return(language, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_language_google(input_text):\n",
    "    \"\"\"\n",
    "    This function uses Google's package 'langdetect' to detect the language\n",
    "    of a sentence.\n",
    "    \"\"\"\n",
    "    likelihood = {}\n",
    "    for item in langdetect.detect_langs(input_text):\n",
    "        likelihood[item.lang] = item.prob\n",
    "    return(likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng_test_string = \"This is an English test string for the function.\"\n",
    "span_test_string = \"Esta es una cadena de prueba en inglés para la función.\" \n",
    "port_test_string = \"Esta é uma string de teste em inglês para a função.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eng_x, eng_y = get_language_stopword(eng_test_string)\n",
    "span_x, span_y = get_language_stopword(span_test_string)\n",
    "port_x, port_y = get_language_stopword(port_test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dutch': 1, 'norwegian': 1, 'english': 4, 'danish': 1, 'portuguese': 1, 'german': 1}\n",
      "english\n",
      "{'italian': 2, 'danish': 2, 'norwegian': 2, 'portuguese': 2, 'spanish': 6, 'dutch': 2, 'turkish': 2, 'hungarian': 1, 'finnish': 1, 'french': 4, 'swedish': 2, 'german': 1}\n",
      "spanish\n",
      "{'spanish': 3, 'italian': 1, 'turkish': 1, 'norwegian': 1, 'french': 1, 'english': 1, 'dutch': 1, 'danish': 1, 'hungarian': 2, 'portuguese': 5, 'swedish': 1}\n",
      "portuguese\n"
     ]
    }
   ],
   "source": [
    "print(eng_y)\n",
    "print(eng_x)\n",
    "print(span_y)\n",
    "print(span_x)\n",
    "print(port_y)\n",
    "print(port_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eng_google = get_language_google(eng_test_string)\n",
    "span_google = get_language_google(span_test_string)\n",
    "port_google = get_language_google(port_test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n",
      "es\n",
      "pt\n"
     ]
    }
   ],
   "source": [
    "print(eng_google)\n",
    "print(span_google)\n",
    "print(port_google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_into_sentences(text):\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    if \"Ph.D\" in text: \n",
    "        text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "    text = re.sub(\"\\s\" + caps + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(caps + \"[.]\" + caps + \"[.]\" + caps + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(caps + \"[.]\" + caps + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + caps + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = sentences[:-1]\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset()\n"
     ]
    }
   ],
   "source": [
    "print(get_etexts('title', 'Moby Dick'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_metadata_cache'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-215-c50bf0d6a892>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgutenberg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_metadata_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_metadata_cache'"
     ]
    }
   ],
   "source": [
    "from gutenberg.acquire import get_metadata_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gutenberg.query import get_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset()"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metadata('title', 52336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = '../data/'\n",
    "files = [f for f in listdir(data_path) if isfile(join(data_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "for item in langdetect.detect_langs(span_test_string+eng_test_string):\n",
    "    d[item.lang] = item.prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:requests.packages.urllib3.connectionpool:Starting new HTTP connection (1): www.gutenberg.lib.md.us\n",
      "INFO:requests.packages.urllib3.connectionpool:Starting new HTTP connection (1): www.gutenberg.lib.md.us\n",
      "INFO:requests.packages.urllib3.connectionpool:Starting new HTTP connection (1): www.gutenberg.lib.md.us\n"
     ]
    }
   ],
   "source": [
    "text = strip_headers(load_etext(52336)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"MOBY DICK; OR THE WHALE\\n\\nBy Herman Melville\\n\\n\\n\\n\\nOriginal Transcriber's Notes:\\n\\nThis text is a combin\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_encoder(self, my_string):\n",
    "    try:\n",
    "        return unicode(my_string).encode()\n",
    "    except UnicodeDecodeError:\n",
    "        return 'DecodeError'.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/candide.txt') as f:\n",
    "    content = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_text = \" \".join(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = split_into_sentences(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleaned_sentences = []\n",
    "for sentence in sentences:\n",
    "    words = sentence.strip().split(\" \")\n",
    "    if len(words) >= 2:\n",
    "        cleaned_sentences.append(\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(cleaned_sentences, columns=['Sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['google_language'] = df['Sentences'].apply(lambda x: get_language_google(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fi': 0.9999972065764102}"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['google_language'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200.16"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((139*6)/5)*1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../Code/sentence_langs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = test[list(test.columns[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>num_words</th>\n",
       "      <th>google_language</th>\n",
       "      <th>book_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>?The Project Gutenberg EBook of Candide, by Vo...</td>\n",
       "      <td>42</td>\n",
       "      <td>{'en': 0.9999959904510038}</td>\n",
       "      <td>candide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You may copy it, give it away or re-use it und...</td>\n",
       "      <td>28</td>\n",
       "      <td>{'en': 0.9999967884658534}</td>\n",
       "      <td>candide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you are not located in the United States, y...</td>\n",
       "      <td>27</td>\n",
       "      <td>{'en': 0.9999968148627227}</td>\n",
       "      <td>candide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Title: Candide    Author: Voltaire    Translat...</td>\n",
       "      <td>93</td>\n",
       "      <td>{'et': 0.7142846803585882, 'fi': 0.28571493117...</td>\n",
       "      <td>candide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VOLTAIRE      Suom.</td>\n",
       "      <td>7</td>\n",
       "      <td>{'pt': 0.14285637648722269, 'fi': 0.8571400997...</td>\n",
       "      <td>candide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  num_words  \\\n",
       "0  ?The Project Gutenberg EBook of Candide, by Vo...         42   \n",
       "1  You may copy it, give it away or re-use it und...         28   \n",
       "2  If you are not located in the United States, y...         27   \n",
       "3  Title: Candide    Author: Voltaire    Translat...         93   \n",
       "4                                VOLTAIRE      Suom.          7   \n",
       "\n",
       "                                     google_language book_name  \n",
       "0                         {'en': 0.9999959904510038}   candide  \n",
       "1                         {'en': 0.9999967884658534}   candide  \n",
       "2                         {'en': 0.9999968148627227}   candide  \n",
       "3  {'et': 0.7142846803585882, 'fi': 0.28571493117...   candide  \n",
       "4  {'pt': 0.14285637648722269, 'fi': 0.8571400997...   candide  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence           Oy Weilin & G??s kirjapainossa.\n",
       "num_words                                        5\n",
       "google_language         {'fi': 0.9999965275396452}\n",
       "book_name                                  candide\n",
       "Name: 6, dtype: object"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['google_lanuga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
